{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6679884-ea36-4269-8bd6-d75bdaf6c7d1",
   "metadata": {},
   "source": [
    "В данной работе описан алгоритм SHAP (Shapley additive explanations) для интерпретации моделей машинного обучения. Работа во многом основана на более ранней работе, в которой описан алгоритм LIME ([Ribeiro et al., 2016](https://arxiv.org/abs/1602.04938)), поэтому этот обзор является продолжением [обзора на LIME]($“Why Should I Trust You?”: Explaining the Predictions of Any Classifier$) и использует обозначения и терминологию из этого обзора.\n",
    "\n",
    "LIME и SHAP могут быть использованы для локальной интерпретации произвольных моделей машинного обучения.\n",
    "- Под *локальностью* понимается интерпретация модели в окрестности некоего конкретного примера $x_0$. Это может помочь понять, почему модель сделала на данном примере такое предсказание (подробнее см. в [обзоре на LIME]($“Why Should I Trust You?”: Explaining the Predictions of Any Classifier$)).\n",
    "- Под *произвольностью* (model-agnostic interpretation) понимается, что мы рассматриваем модель как \"черный ящик\", преобразующий входные данные в выходные, и пытаемся интерпретировать его, изучая его работу на конкретных примерах. При этом мы никак явно не используем информацию о том, как модель устроена \"изнутри\" (хотя неявно эта информация может использоваться при выборе функций $h_{x_0}$ и аппроксимирующей модели $g$).\n",
    "\n",
    "### Additive feature attribution methods\n",
    "\n",
    "Авторы данной работы рассматривают частный случай LIME, когда модель $g$ линейна:\n",
    "\n",
    "$g(x^\\prime) = \\phi_0 + \\sum\\limits_{i=1}^M \\phi_i x_i^\\prime \\tag{1}$\n",
    "\n",
    "В данной формуле $x^\\prime$ - вектор упрощенного представления из нулей и единиц, $x_i^\\prime \\in \\{0, 1\\}$ - отдельные элементы этого вектора, $\\phi_i \\in \\mathbb{R}$ - соответствующие им веса. При этом упрощенное представление исходного примера $x_0$ - это вектор, состоящий из единиц. Формула $(1)$ означает, что каждый признак в упрощенном представлении $x^\\prime$ имеет некий вес, и при наличии этого признака его вес прибавляется к предсказанию. Методам интерпретации, которые используют такую модель, авторы дают название *additive feature attribution methods*. Модель $g$ авторы называют *объясняющей моделью*.\n",
    "\n",
    "Конечно, в некоторых случаях такая аппроксимация будет некорректной (это зависит от модели, задачи, выбранного упрощенного представления), то есть LIME и SHAP имеют хоть и широкую, но ограниченную область применимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e697b-8ba2-4674-9968-34fde09e97c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6d2596b-1c15-4d0f-90d2-071a005a58c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b49845-236f-461f-9413-7bcd41ae0535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
