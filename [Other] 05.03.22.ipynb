{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22eefcb5-03b8-4602-9155-c49a9cc7336a",
   "metadata": {},
   "source": [
    "Предлагаю на обсуждение несколько потенциальных направлений исследований."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932c143-467d-46a0-bbaa-55d828840750",
   "metadata": {},
   "source": [
    "### Обучение языковых моделей\n",
    "\n",
    "Предложение Ивана Бондаренко. Можно обучить русскоязычную версию языковой модели [ERNIE 3.0]($ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation$). Можно также реализовать многозадачное иерархическое обучение, при котором к промежуточным слям нейронной сети присоединяются дополнительные выходные слои для решения промежуточных задач, таких как морфологический анализ, выделение именованных сущностей. Также можно попробовать [модифицировать]($25.01.22$) архитектуру трансформера.\n",
    "\n",
    "**Перспективы.** Позиции в [русскоязычных лидербордах](https://russiansuperglue.com/leaderboard/2) и позиционирование обученной модели как SOTA для определенных классов задач (каких получится).\n",
    "\n",
    "**Монетизация.** Во-первых, можно подать заявку на получение гранта. Но в заявке нужно указывать измеримые цели проекта с конкретными метриками качества, что более характерно для инженерных, но не исследовательских задач. В исследовательских задачах метрика часто неизвестна заранее, и исследование идет методом проб и ошибок. Поэтому непонятно, как в заявке на грант описывать конкретные и измеримые цели проекта так, чтобы их можно было потом достичь.\n",
    "\n",
    "Во-вторых, можно заинтересовать коммерческие компании и предложить им лицензировать обученную модель или метод обучения. Но для этого нужно сначала достичь результата. Впрочем, ничего не мешает связаться с разными компаниями заранее и предложить им совместный оплачиваемый проект, вдруг согласятся.\n",
    "\n",
    "**Проблемы.** Для позиций в лидербордах важным является размер модели, объем и качество подготовки обучающих данных. При этом придется конкурировать с компаниями, имеющими много вычислительных ресурсов (Яндекс, Сбер и т. д.). Как вариант, можно сфокусироваться на создании не самой качественной модели, а на создании самой оптимальной модели по соотношению размера и качества. Но тогда большую роль играет количество и качество обучающих данных, в чем опять-таки придется конкурировать с крупными компаниями, либо сотрудничать с ними. Наиболее правильным с точки зрения методологии было бы создание лидерборда, в котором сравнивались бы модели, обученные на одних и тех же данных. Но такого лидерборда, кажется, нет.\n",
    "\n",
    "**Возможные дальнейшие шаги.** Проверить объем доступных обучающих данных, оценить стоимость обучения. Пообщаться с экспертами и NLP-отделами различных компаний (Сбер, Яндекс и др.), спросить мнений и советов, предложить совместную работу. Попробовать запустить обучение ERNIE 2.0 (код есть в открытом доступе) в качестве тест-драйва."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31d36c-4147-4103-b48e-8acfb4893ec0",
   "metadata": {},
   "source": [
    "### Изучение и обучение мультимодальных систем\n",
    "\n",
    "Различные модальности (изображения, текст и др.) могут дополнять друг друга и формировать более целостную картину мира, чем каждая модальность по отдельности, поэтому мультимодальное обучение кажется многообещающим. В последние пару лет в этой области были достигнуты впечатляющие результаты. (Dall-E, CLIP, [OFA](https://github.com/OFA-Sys/OFA)).\n",
    "\n",
    "Мультимодальное обучение не равно многозадачному, но может быть и многозадачным. Например, в OFA используется много задач (работа с текстами, изображениями, text-to-image, image-to-text) и единая архитектура для всех них, в которой каждая задача формулируется как sequence-to-sequence. При этом было показано, что обученная модель способна решать и новые, ранее не встречающиеся типы задач, по их текстовым описаниям.\n",
    "\n",
    "Можно начать с анализа работы модели OFA (есть [интерактивная версия](https://huggingface.co/OFA-Sys)), наподобие BERT-ологии, примененной к мультимодальным системам:\n",
    "1. Собрать статистику ее ошибок и типов этих ошибок (например, модель путает число объектов, находит на изображении несуществующие объекты и т. д.).\n",
    "2. Если модель ошибается в задаче image captioning, то проверить, как работает детектирование объектов на этой же картинке. При этом важно декомпозировать ошибку, например, в задаче image captioning - понять, является ли ошибка следствием неправильного распознавания объектов, неправильной генерации текста, или же эти два шага неразделимы? Для этого можно анализировать выходные данные промежуточных слоев.\n",
    "3. Изучить, как меняются выходы промежуточных слоев и ответ модели при движении объекта в кадре.\n",
    "4. Изучить способность к систематическому обобщению, то есть к независимости ответа модели от различных посторонних деталей. Сравнить уровень систематического обобщения в мультимодальных системах по сравнению с одномодальными CV- и NLP-моделями.\n",
    "\n",
    "Изучив модель и определив проблемы, можно попробовать улучшить архитектуру или способ обучения. Например, можно попробовать явно разбить задачу работы с изображениями на два шага: формирование внутренних представлений объектов, и затем выполнение собственно требуемой задачи (детектирование, классификация, создание подписи к изображению и так далее).\n",
    "\n",
    "Эта задача привлекательна тем, что она интересна и при этом многие ее шаги довольно просты (например, изучать ответ модели на разных текстах и изображениях). Поэтому можно подключать к исследованию студентов без опыта в ML. Эта задача способна заинтересовать студентов, а заинтересованный студент - это в перспективе хороший специалист и исследователь. Кроме того, сама задача лежит на переднем крае и в мейнстриме современного глубокого обучения, и здесь явно есть перспективы.\n",
    "\n",
    "**Перспективы.** Основной перспективой является научная публикация, остальные перспективы зависят от того, какой результат даст исследование и удастся ли найти способы улучшить мультимодальные модели.\n",
    "\n",
    "**Монетизация.** В целом все так же, как в предыдущей идее проекта. Так же можно подать заявку на грант, но это имеет смысл делать после того, как будет исследована модель, найдены проблемы, предложены их решения, определены конкретные цели (метрики качества) и конкретные области применения обученной модели, а эти шаги могут занять много времени."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd881af-0659-47a2-996f-84bbaeb5faad",
   "metadata": {},
   "source": [
    "### ML на табличных данных\n",
    "\n",
    "В табличных данных наблюдается излишнее количество бенчмарков при отсутствии стандартизации, что авторы статей используют в свою пользу. Например, возьмем 2 источника: документацию [CatBoost](https://github.com/catboost/benchmarks/tree/master/quality_benchmarks) и статью [Revisiting Deep Learning Models for Tabular Data](https://arxiv.org/pdf/2106.11959.pdf) (тоже от Яндекса). Оба источника предлагают свои бенчмарки примерно по 10 датасетов, при этом в них есть лишь один общий датасет (Adult income estimation для бинарной классификации). Но по этому датасету разные метрики: первый источник использует logloss, второй accuracy.\n",
    "\n",
    "По первому источнику (logloss) ранжирование качества такое: Tuned CatBoost > Default CatBoost > Tuned XGBoost > Default XGBoost. По второму источнику (accuracy) ранжирование совсем другое: Default XGBoost ~ Tuned CatBoost > Default CatBoost > Tuned XGBoost (при этом точность XGBoost после настройки параметров у них уменьшилась).\n",
    "\n",
    "Кроме того оба бенчмарка используют набор датасетов с очень ограниченным разнообразием (по кол-ву примеров и пр.), при этом не строятся графики зависимости точности от кол-ва обучающих примеров и кол-ва деревьев.\n",
    "\n",
    "Изучив существующие бенчмарки, можно предложить собственный, и если он будет объективно лучше (разнообразнее, детальнее), то предложить использовать его.\n",
    "\n",
    "**Перспективы.** Бенчмарк может создаваться с целью сравнить качество и особенности работы множества существующих ML-моделей на табличных данных, а также предоставить воспроизводимый код для сравнения этих моделей, и тем самым способствовать разработке новых методов. Более конкретно:\n",
    "\n",
    "1. Предоставить разнообразную коллекцию датасетов на табличных данных, в том числе реалистичные данные с пропущенными признаками, выбросами и сдвигом данных.\n",
    "2. Предоставить детальное описание для каждого датасета.\n",
    "3. Создать библиотеку для легкого скачивания и использования этих датасетов.\n",
    "4. Создать интерактивную систему оценки моделей, по аналогии с superGLUE.\n",
    "5. Предоставить детальную информацию о моделях и их предсказаниях (а не только точности), например, partial dependency plots, зависимость предсказаний от количества обучающих примеров, количества деревьев и/или времени обучения, корреляция предсказаний различных моделей и прочее.\n",
    "\n",
    "В целом программисты, как мне кажется, не любят писать много кода и любят использовать готовое. Поэтому если ставить такую цель, то нужно сосредоточиться на легкости использования. Библиотека может содержать в себе разнообразный набор датасетов с легкой процедурой загрузки и обработки, возможности анализа предсказаний одной строкой кода, например partial dependency plot и прочее. Даже если кто-то не захочет использовать ее как официальный бенчмарк, то по крайней мере она будет полезна широкому кругу ML-разработчиков.\n",
    "\n",
    "**Монетизация.** В этой задаче можно предложить сотрудничество Яндексу, так как у их инженеров есть опыт подобных исследований, например, статья [Revisiting Deep Learning Models for Tabular Data](https://arxiv.org/pdf/2106.11959.pdf). Возможно, даже попросить денег. Если в Яндексе занимались подобными исследованиями, значит их интересует эта тема, им это нужно и может быть оплачено.\n",
    "\n",
    "**Тестирование новых моделей.** После создания бенчмарка станет намного проще и удобнее тестировать новые модели. \n",
    "\n",
    "1. Мне кажутся перспективными аддитивные модели на подмножествах признаков - в экспериментах с датасетом california housing они достигали очень хорошей точности при полной интерпретируемости. Обучая сумму нейронных сетей в следующем виде: f1(x6, x7)+f2(x2)+f3(x0, x5)+f4(x1,x5)+f5(x0,x1)+f6(x3), удавалось превысить точность обычной нейронной сети, использующей все признаки. Возможно такая декомпозиция может служить [формой регуляризации]($О свойствах решающих деревьев$). Подобными исследованиями недавно [занимался](https://arxiv.org/abs/2004.13912) Джеффри Хинтон.\n",
    "2. Трансформеры достигают на табличных данных неплохой точности. Можно попробовать обучить трансформер в стиле BERT на отдельно взятой задаче, или даже предобучить его на множестве разных табличных датасетов. Тем самым мы получим модель, которая сможет \"из коробки\" работать с пропущенными признаками, оценивать вероятность входных данных и уверенность в предсказаниях. Предобучение с дальнейшим файн-тюнингом может увеличить точность, по сравнению с обучением модели на задаче с нуля (как сейчас принято делать)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b18cac-3fa4-4e5e-972f-f1fd60df26f3",
   "metadata": {},
   "source": [
    "### Другие направления исследований\n",
    "\n",
    "**Representation learning на видеозаписях.** Одним из возможных путей к созданию ML-систем следующего поколения может стать обучение систем, способных анализировать видео и предсказывать следующие события (далее чем несколько кадров), в том числе в текстовом виде. Такие системы могут быть способы отличать статистические зависимости от причинно-следственных связей, а также соотносить текст с происходящими событиями. Похожая задача возникает при обучении агентов, которым необходимо предсказывать последствия своих и чужих действий. Агента может заменить на наблюдателя, задача которого - лишь предсказывать последствия чужих действий.\n",
    "\n",
    "**Ускорение обучения нейронных сетей.** В экспериментах я замечал, что по истории значений некоего веса в нейронной сети в ходе обучения можно предсказать, как этот вес будет меняться дальше, обучив для этого отдельную модель. Например, модель может использовать значения веса на шагах с N-го по N+1000-й, и предсказывать значение веса на шаге N+2000. Используя такую модель, удавалось улучшить точность сети на валидации, предсказав значения весов через 1000 шагов и установив эти значения. Применение такого способа могло бы существенно ускорить процесс обучения нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb60ef-1e68-400f-b235-51e9ddead6bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
