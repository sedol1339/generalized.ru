{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52b4f5e-8e2d-40a5-a614-e7fae7f701bf",
   "metadata": {},
   "source": [
    "Эта статья посвящена следующему вопросу: как доказать, что некая функция потерь является наилучшей в некой задаче? Интуитивно мне всегда казалось, что теория машинного обучения не дает ответа на этот вопрос, и выяснять это нужно либо экспериментально, либо вводя какую-то метрику схожести на целевой переменной на основе знаний из предметной области.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ed811-7894-4c2c-9c8e-da45b8b7f15b",
   "metadata": {},
   "source": [
    "Выбор той или иной функции потерь в задачах машинного обучения может быть либо сделан экспериментально, либо обоснован теоретическими рассуждениями разного рода. Например следующими:\n",
    "\n",
    "**Легкость оптимизации**\n",
    "\n",
    "Часто требуется, чтобы функция потерь была дифференцируемой, иначе многие алгоритмы оптимизации просто не будут работать. Оптимизация часто осуществляется градиентным спуском, и потому полезно исследовать *градиенты, которые дает функция потерь*. Пара примеров:\n",
    "\n",
    "*Пример 1.* Функция потерь MAE дает один и тот же по модулю градиент, независимо от величины ошибки. В функции потерь MSE, напротив, градиент тем меньше, чем меньше величина ошибки. Это свойство часто улучшает сходимость методов оптимизации. Также оно соответствует здравому смыслу: чем больше ошибка, тем сильнее ее нужно \"штрафовать\". Хотя такие рассуждения следует применять с осторожностью.\n",
    "\n",
    "*Пример 2.* В задаче бинарной классификации мы можем использовать бинарную кроссэнтропию или MSE. Предположим, что до функции потерь находится сигмоида $\\sigma(x)$. Посчитаем производную функции потерь по аргументу сигмоиды для случая, когда верный ответ равен 1. В случае бинарной кроссэнтропии:\n",
    "\n",
    "$\\cfrac{\\partial {loss}}{\\partial x} = 1 - \\sigma(x)$\n",
    "\n",
    "В случае MSE:\n",
    "\n",
    "$\\cfrac{\\partial {loss}}{\\partial x} = -2\\sigma(x)(1-\\sigma(x))^2$\n",
    "\n",
    "При $x \\to -\\infty$ (то есть когда модель выдает уверенный неправильный ответ) при бинарной кроссэнтропии производная стремится к 1, а при MSE производная стремится к нулю. Это означает, что при сочетении сигмоиды и MSE уверенные неправильные ответы практически не корректируются (градиент близок к нулю), что может негативно сказаться на качестве обучения. Это аргумент в пользу того, чтобы при использовании сигмоиды выбирать бинарную кроссэнтропию, а не MSE.\n",
    "\n",
    "Обобщая описанный выше подход, можно даже не выбирать функцию потерь, а выбирать напрямую ее производную, так как только она используется при оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8cb9b-60b7-4b80-871b-3ad9d6cdc474",
   "metadata": {},
   "source": [
    "**Соображения теории вероятностей**\n",
    "\n",
    "С позиции теории вероятностей модель машинного обучения можно рассматривать как [статистическую модель]($Статистические модели$) для оценки условной вероятности $P(y|x)$ (то есть зная $x$ оценить вероятности разных значений $y$). Модель представляется как параметризованное семейство гипотез:\n",
    "\n",
    "$\\{P_\\theta(y|x) \\,|\\, \\theta \\in \\Theta\\}$\n",
    "\n",
    "Для поиска оптимальных параметров $\\theta$ можно использовать метод максимального правдоподобия, то есть искать такое $\\theta$, при котором верноятность наблюдаемых данных (обучающего датасета) максимальна. Поиск максимума правдоподобия равносилен поиску минимума от минус логарифма правдоподобия. Также можно сопоставить разным значениям $\\theta$ разные априорные вероятности, то есть добавить в модель регуляризацию. В таком случае ищется апостериорный максимум. Более подробно об этом я писал в [статье о статистических моделях]($Статистические модели$).\n",
    "\n",
    "В задаче классификации модель напрямую оценивает $P(y|x)$, то есть при заданном $x$ ищет вероятности для каждого $y$. Максимизация правдоподобия в этом случае эквивалентна максимизации логарифма $P(y = y_{true}|x)$, что соответствует формуле для категориальной и бинарной кроссэнтропии. Это обосновывает применение кроссэнтропии как функции потерь в задаче классификации.\n",
    "\n",
    "В задаче регрессии модель как параметризованное семейство гипотез $P(y|x)$ можно задать как нормальное распределение, мат. ожидание которого расчитывается с помощью параметров $\\theta$, а дисперсию можно задать произвольно:\n",
    "\n",
    "$P_\\theta(y|x) = \\mathcal{N}(y; f(x, \\theta), \\sigma)$\n",
    "\n",
    "Если в данном выражении мы распишем формулу для нормального распределения, то увидим, что максимизация правдоподобия для пары $(x, y)$ из датасета равносильна минимизации MSE между $f(x, \\theta)$ и $y$. Изменение параметра $\\sigma$ при этом равносильно масштабированию функции потерь или, что то же самое, изменению learning rate. Это обосновывает применение функции потерь MSE в задачах регрессии.\n",
    "\n",
    "Впрочем, вместо нормального распределения можно задать и любое другое. Выбор именно *нормального* распределения в некоторых случаях может быть неоптимальным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93b1a9-2aaf-4cae-9813-e19d0f5f889e",
   "metadata": {},
   "source": [
    "**Соображения теории информации**\n",
    "\n",
    "Метод максимального правдоподобия можно рассматривать как минимизацию расхождения Кульбака-Лейблера между [эмпирическим распределением](https://en.wikipedia.org/wiki/Empirical_distribution_function) и задаваемым моделью распределением $P_\\theta(y|x)$. Эмпирическое распределение - это дискретное распределение вероятностей, полученное напрямую из обучающих данных. Для пары $(x_i, y_i)$ из обучающих данных эмпирическое распределение задается следующим образом:\n",
    "\n",
    "$P(y, x_i) = \\begin{cases} 1, y = y_i \\\\ 0, y \\neq y_i \\end{cases}$\n",
    "\n",
    "Если мы имеем два распределения $P$ и $Q$, то минимизация по $Q$ расхождения Кульбака-Лейблера между $P$ и $Q$ равносильна минимизации кроссэнтропии между $P$ и $Q$. Кроссэнтропия определяется по следующей формуле для дискретного и непрерывного распределений:\n",
    "\n",
    "$H(P, Q) = -\\sum\\limits_{x \\in X} P(x)\\log Q(x)$\n",
    "\n",
    "$H(p, q) = -\\int\\limits_X p(x)\\log q(x)\\,dx$\n",
    "\n",
    "В задаче классификации это и есть бинарная/категориальная кроссэнтропия, используемая часто в качестве функции потерь.\n",
    "\n",
    "В случае регрессии мы задавали плотность вероятности $P_\\theta(y|x)$ следующим образом:\n",
    "\n",
    "$P_\\theta(y|x) = \\mathcal{N}(y; f(x, \\theta), \\sigma)$\n",
    "\n",
    "Плотность вероятности эмпирического распределения задается функцией Дирака. Прямым подсчетом можно увидеть, что кроссэнтропия между эмпирическим распределением и задаваемым моделью распределением равна MSE между $f(x, \\theta)$ и $y$.\n",
    "\n",
    "Таким образом, если обучающая выборка доступна в виде пар $(x, y)$, то есть в виде эмпирического распределения, то максимизация правдоподобия и минимизация кроссэнтропии - одно и то же. Впрочем, понятие кроссэнтропии основано на теории информации, которая первоначально использовалась в теории кодирования сигналов. Сложно сказать насколько правомерным является использование тех же идей в задачах статистического вывода, то есть в совсем другой области."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c7446-8026-4377-8966-9245f05901d5",
   "metadata": {},
   "source": [
    "**Функция потерь как выражение метрики на целевой переменной**\n",
    "\n",
    "Отличие классификации от регрессии в том, что в задаче классификации все классы считаются одинаково непохожими друг на друга, тогда как в задаче регрессии чем ближе два значения, тем более они схожи друг с другом. Это можно рассматривать как применения гипотезы компактности к целевым данным. Именно это определяет тот факт, что в классификации и регрессии применяются разные форматы выходных данных и разные функции потерь.\n",
    "\n",
    "Метрика схожести может быть и более сложной, например в случае иерархической классификации мы заранее знаем, что некоторые классы более похожи друг на друга, чем другие. Например, в задаче классификации изображений перепутать породу собаки на изображении является в меньшей степени ошибкой, чем спутать собаку с автомобилем. Мы можем явно указать метрику расстояния между классами и создать нестандартный формат выходных данных и/или нестандартную функцию потерь, учитывающую эту метрику. Тогда наша задача будет иметь черты и классификации, и регрессии.\n",
    "\n",
    "Таким образом, *априорная метрика схожести на множестве целевых данных определяет оптимальный формат выходных данных и функцию потерь.* Тем самым мы выбираем априорные гипотезы о виде распределения $P(y|x)$. В задаче классификации распределение $P(y|x)$ может иметь какой угодно вид. В задаче регрессии из-за гипотезы компактности можно предположить, что существуют такие параметры $\\theta$, что $P(y|x) = \\mathcal{N}(y; f(x, \\theta), \\sigma)$, и решение мы ищем именно в таком виде (вместо $\\mathcal{N}$ может быть и другое распределение).\n",
    "\n",
    "В принципе задачу классификации можно решать и как регрессию, напрямую предсказывая номер класса и округляя его до целого. Это по сути будет означать, что мы применяем к номеру класса гипотезу компактности: классы с похожими номерами более схожи. Если это безосновательно (а как правило так и есть), то и решение получится существенно хуже по метрике качества. И наоборот, задачу регрессии можно решать как задачу классификации, разбив числовую прямую на интервалы и предсказывая вероятность принадлежности объекта каждому интервалу. Тем самым мы избавляемся от гипотезы компактности. Если это безосновательно, то решение также получится существенно хуже. Однако если доступно очень большое количество и разнообразие обучающих данных, то априорные гипотезы перестают играть столь важную роль. В принципе при огромном объеме обучающих данных и высокой выразительной способности модели мы можем решать классификацию как регрессию или наоборот, и получим хорошую точность."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
