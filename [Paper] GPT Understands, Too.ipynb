{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc50957-c961-4e62-80d6-f7df025e98cf",
   "metadata": {},
   "source": [
    "Процесс обучения NLP-моделей как правило состоит из двух шагов: предобучения и адаптации под какую-либо конкретную задачу. Наиболее распространенным способом адаптации является файн-тюнинг, но существуют и другие способы, такие как in-context learning. Авторы данной работы предлагают еще один способ адаптации моделей под конкретные задачи, названный P-learning. Далее сравним все перечисленные способы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d64b33-1387-46c1-883f-4759a4f8d02b",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "При файн-тюнинге модель дообучается на размеченных данных для конкретной задачи. Однако авторы утверждают, что большие языковые модели (такие как GPT-3) быстро запоминают все обучающие примеры, что снижает эффективность файн-тюнинга. В целом было замечено, что GPT-подобные модели не достигают на задачах понимания естественного языка (NLU) такого же качества, как BERT-подобные модели.\n",
    "\n",
    "> For long, researchers have observed that GPT-style models perform poorly for NLU tasks with fine-tuning, and thus assumed that they are not suitable for language understanding in nature.\n",
    "\n",
    "Есть правда еще один метод дообучения (*feature-based*), когда для конкретной задачи создается и обучается отдельный выходной слой, при этом остальные веса модели не меняются - этот подход авторы данной работы не упоминают."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0113983-f8f4-48b5-8438-d99822692e17",
   "metadata": {},
   "source": [
    "### In-context learning\n",
    "\n",
    "Пусть наша задача - построение вопросно-ответной системы, и мы имеем N обучающих примеров из вопросов и ответов на них. Вместо того, чтобы выполнять файн-тюнинг модели с помощью этих данных, мы можем просто сформировать следующий текстовый запрос:\n",
    "\n",
    "*\"вопрос1; ответ1; ..., вопросN; ответN; вопрос\"*\n",
    "\n",
    "Последним идет вопрос, на который мы хотим получить ответ. Опционально перед примерами можно добавить также формулировку задачи в текстовом виде. Передав получившийся текст на вход модели, на выходе мы получаем ответ на него. Особенно хорошо этот способ работает для больших моделей, вроде GPT-3. В зависимости от количества примеров такой способ называется *zero-shot*, *one-shot* или *few-shot in-context learning*. Ниже приведены примеры из статьи, посвященной модели GPT-3 ([Brown et al., 2020]($Language Models are Few-Shot Learners$))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020cae5-717b-459c-85ad-8fdd0d3ef70c",
   "metadata": {},
   "source": [
    "<img src=\"assets/incontext.jpg\" width=\"700\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2964d7-3be5-459f-85a3-b7a71c520707",
   "metadata": {},
   "source": [
    "При этом не происходит обновления весов модели градиентным спуском, поэтому такой способ не является обучением в стандартном понимании этого термина применительно к нейронным сетям, но в каком-то смысле это все же обучение. Авторы GPT-3 рассматривают такой процесс как *meta-learning* (см. [Brown et al., 2020]($Language Models are Few-Shot Learners$)).\n",
    "\n",
    "В каких-то случаях такой способ может быть предпочтительнее, чем файн-тюнинг. Например, задачей может являться получение ответов на вопросы (расположение городов, исторические факты и пр.) - такие ответы требуют различных знаний о мире, накопленных в процессе предобучения. При файн-тюнинге веса сети меняются, при этом есть опасность, что часть знаний \"сотрется\" (а именно знания о тех фактах, которые не попали в обучающую выборку).\n",
    "\n",
    "> ...in terms of knowledge probing, many facts can only be hard-coded rather than inferenced by language models. The fine-tuning of parameters might result in catastrophic forgetting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f14c32-43a9-461c-80b8-6c35abc5aba9",
   "metadata": {},
   "source": [
    "### Manual promting\n",
    "\n",
    "Под термином manual promting авторы данной работы понимают разновидность zero-shot in-context learning, при которой особое внимание уделяется подбору текстового описания задачи. Таким образом мы ищем наилучший способ \"дать понять\" модели чего мы хотим. На иллюстрации ниже показано несколько примеров текстового описания задачи, где вместо [X] подставляются исходные данные, а вместо [Y] целевые данные. Показана также точность работы такого метода для модели `bert-base-cased` на датасете из городов и стран. Можно видеть, что разные формулировки задачи дают существенно разную точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38647fe7-8f2e-46da-8fc6-a63b652bfce5",
   "metadata": {},
   "source": [
    "<img src=\"assets/promting.png\" width=\"300\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f361b4-876b-4e97-a761-a3950a40453a",
   "metadata": {},
   "source": [
    "Каждое описание задачи состоит из последовательности токенов. Например, для BERT-подобных моделей формат может быть следующим:\n",
    "\n",
    "`<promt1>` [X] `<promt2>` [Y] `<promt3>`\n",
    "    \n",
    "Здесь `<promt1>`, `<promt2>`, `<promt3>` - токены, описывающие задачу в текстовом виде (как на иллюстрации выше), [X] - входные данные, [Y] - токен [MASK], который модель должна заменить на ответ. Здесь, правда, есть ограничение: ответ должен помещаться в один токен. Для GPT-подобных моделей формат может быть следующим:\n",
    "\n",
    "`<promt1>` [X] `<promt2>`\n",
    "\n",
    "Продолжение текста, сгенерированное моделью, считается ответом.\n",
    "\n",
    "В различных работах были предложены методы автоматического подбора подходящих описаний задачи (на основе точности на валидационном датасете).\n",
    "\n",
    "Можно объединить файн-тюнинг и manual promting, подбирая сначала оптимальное текстовое описание задачи (и таким образом задавая формат входных данных), и затем выполняя файн-тюнинг сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a588398-2131-4ab4-a112-ae488b18b2a6",
   "metadata": {},
   "source": [
    "### P-tuning\n",
    "\n",
    "Вместо того, чтобы подбирать токены, можно напрямую оптимизировать их эмбеддинги градиентным спуском - в этом и заключается метод P-tuning. При этом мы можем получить эмбеддинги, которые не соответствуют ни одному токену в словаре, но качество получаемого решения оказывается выше, чем при manual promting, что показывают авторы данной работы.\n",
    "\n",
    "Если сравнивать P-tuning и fine-tuning, то отличие в следующем: если при файн-тюнинге оптимизируются веса сети, то при P-tuning оптимизируются дополнительные вектора-эмбеддинги, подаваемые на вход модели.\n",
    "\n",
    "*Примечание.* Как мне кажется, для GPT-подобных моделей формат `<promt1>` [X] `<promt2>` можно без потери общности заменить на `<promt1>` [X], так как `<promt1>` и `<promt2>` отличаются только позиционными эмбеддингами, и таким образом оптимизируется сумма случайного вектора и позиционного эмбеддинга, что эквивалентно оптимизации просто случайного вектора.\n",
    "\n",
    "Можно также провести параллель с [Lu et al., 2021]($Pretrained Transformers as Universal Computation Engines$), где предобученный трансформер с замороженными весами обучали решать различные задачи, оптимизируя подаваемые на вход вектора эмбеддинги (в этой работе оптимизировался также выходной слой трансформера и параметры слоев LayerNormalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149be652-e446-492d-ba83-a260b16ce35c",
   "metadata": {},
   "source": [
    "Авторы предлагают еще одну модификацию (см. раздел 3.2 статьи): те вектора-эмбеддинги, которые оптимизируются в ходе P-tuning, перед подачей на вход трансформера пропускаются через BiLSTM, и оптимизируются также веса этой сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46111353-d584-4167-adc2-e67c3a0c9de6",
   "metadata": {},
   "source": [
    "### Сравнение эффективности\n",
    "\n",
    "Авторы сравнивают на задачах из бенчмарка SuperGLUE следующие подходы:\n",
    "- Fine-tuning\n",
    "- MP zero-shot (Manual promting)\n",
    "- MP fine-tuning (Manual promting + fine-tuning)\n",
    "- P-tuning\n",
    "\n",
    "Ниже показана средняя точность по 7 задачам из бенчмарка SuperGLUE (более подробные таблицы можно найти в статье)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc0e48-b68f-4f52-b157-ce96f80fd6c6",
   "metadata": {},
   "source": [
    "<img src=\"assets/ptuning.jpg\" width=\"550\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84649bba-fcc5-4eed-8631-abe238002c03",
   "metadata": {},
   "source": [
    "Как в случае *base-sized models*, так и в случае *large-sized models* видна одна и та же закономерность: при файн-тюнинге BERT дает лучший результат, чем GPT, тогда как при P-tuning, наоборот, GPT показывает наилучший результат. При этом P-tuning улучшает результат и для модели BERT.\n",
    "\n",
    "Manual promting + fine-tuning показывает результат, сопоставимый с P-tuning, но при этом также меняются веса модели, тогда как при P-tuning веса модели не меняются."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
