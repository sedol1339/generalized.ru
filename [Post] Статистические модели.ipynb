{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b146e0-3064-4be9-b39d-81ce6322da1b",
   "metadata": {},
   "source": [
    "В этой статье мы разберем понятие статистической модели, которое лежит в основе многих задач статистики и машинного обучения.\n",
    "\n",
    "Для дальнейшего изложения понадобится повторить базовые понятия теории вероятностей: [распределение](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9) и выборка. [Непрерывное](http://mathprofi.ru/nepreryvnaya_sluchaynaya_velichina.html) распределение можно задать функцией плотности вероятности, [дискретное](http://mathprofi.ru/sluchainaya_velichina.html) - функцией вероятности каждого элемента. Выборкой из распределения размером $N$ называется $N$ элементов, полученных из распределения. Это не обязательно числа, а могут быть вектора или даже изображения, в зависимости от того, на каком множестве задано наше распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd289ac-5884-44b6-a963-71aa2b36396c",
   "metadata": {},
   "source": [
    "### Статистическая модель\n",
    "\n",
    "Статистическая модель вводятся для ответа на вопрос: *из какого распределения получена имеющаяся выборка данных*? Пусть существует некое распределение $\\Phi$, которое нам неизвестно. Мы имеем выборку размером N элементов из этого распределения $X = \\{X_i\\}_{i=1}^N$. Мы вводим параметризованное семейство распределений $\\{\\phi_\\theta | \\theta \\in \\Theta\\}$, используя некую известную нам функцию $\\phi$. При этом мы надеемся, что искомое распределение $\\Phi$ принадлежит множеству ${\\phi_\\theta}$ или по крайней мере его можно аппроксимировать элементами этого множества. Задача состоит в том, чтобы подобрать оптимальные параметры $\\theta$, при которых выборка $X$ наиболее правдоподобна.\n",
    "\n",
    "Статистическая модель - это пара из выборки $X$ и семейства распределений $\\{\\phi_\\theta | \\theta \\in \\Theta\\}$. Таким образом, модель ничего не говорит об оптимальных значениях параметров, а лишь описывает среди какого множества распределений мы выполняем поиск. То есть модель является постановкой задачи, а не ее решением.\n",
    "\n",
    "**Пример 1**. Мы имеем выборку $X$, полученную из нормального распределения $\\mathcal{N}_{\\mu, \\sigma}$ с неизвестными параметрами $\\mu, \\sigma$. Задача - оценить эти параметры. Моделью в этом случае выглядит так: $(X, \\{\\mathcal{N}_{\\mu, \\sigma} | \\mu \\in \\mathbb{R}, \\sigma \\in \\mathbb{R}\\})$. Заметим, что если выборка $X$ на самом деле была получена не из нормального распределения, то наша модель неадекватна.\n",
    "\n",
    "**Пример 2**. Мы имеем изображение звездного поля, полученное с помощью телескопа. Изображение можно рассматривать как сумму попавших в объектив фотонов, каждый из которых является выборкой из распределения $\\Phi$, которое является суммой [функций рассеяния точки](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D1%80%D0%B0%D1%81%D1%81%D0%B5%D1%8F%D0%BD%D0%B8%D1%8F_%D1%82%D0%BE%D1%87%D0%BA%D0%B8). Каждая функция рассеяния соответствует одной звезде, а коэффициент перед ней соответствует яркости звезды. Нужно по изображению оценить координаты звезд и их яркость, то есть найти параметры распределения $\\Phi$. Это может быть сложной задачей если звезды расположены настолько близко, что их функции рассеяния \"сливаются\" друг с другом.\n",
    "\n",
    "**Пример 3**. Мы имеем набор изображений рукописных цифр 28x28 пикселей [MNIST](https://ru.wikipedia.org/wiki/MNIST_(%D0%B1%D0%B0%D0%B7%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)). Этот набор является выборкой из распределения вероятностей $\\Phi$ всех возможных рукописных изображений цифр. Если мы сможем аппроксимировать $\\Phi$, то сможем генерировать новые цифры. Можно рассмотреть и немного другой пример: мы имеем выборку из распределения $\\Phi$, заданного на множестве пар (изображение, номер цифры). То есть мы имеем изображения и ответы к ним: какая цифра изображена. Это значит, что плотность вероятности $\\Phi$ имеет следующий вид: \n",
    "\n",
    "$\\Phi: \\mathbb{R}^{28 \\times 28} \\times \\{0, 1, 2, \\ldots, 9\\} \\to \\mathbb{R}$.\n",
    "\n",
    "Аргументами функции является изображение ($\\mathbb{R}^{28 \\times 28}$) и цифра от 0 до 9, значением функции является плотность вероятности появления такой пары в распределении. Если мы найдем $\\Phi$ или хотя бы сможем его аппроксимировать, то мы решим задачу распознавания цифр. Например, по заданному изображению мы переберем все возможные \"ответы\" и найдем тот ответ, для которого плотность вероятности наибольшая, и так определим какая цифра изображена.\n",
    "\n",
    "### Статистические модели в машинном обучении\n",
    "\n",
    "Распознавание MNIST, приведенное в примере выше - типичная задача машинного обучения. Это означает, что *модели машинного обучения обычно тоже являются статистическими моделями*. С их помощью мы пытаемся аппроксимировать неизвестное нам распределение вероятностей. Отличие статистики от машинного обучения лишь в том, что в машинном обучении искомые распределения вероятностей намного сложнее, поэтому искать их нужно другими методами.\n",
    "\n",
    "Рассмотрим задачу машинного обучения, имеющую целевые данные $Y$ (что нужно предсказать) и исходные данные $X$ (на основании каких данных нужно сделать предсказание). Распределение на множестве пар (исходные + целевые данные) называется порождающим распределением. Саму модель машинного обучения можно описать в разных вариантах:\n",
    "\n",
    "1. $Y(X)$\n",
    "2. $P(Y|X)$\n",
    "3. $P(X, Y)$.\n",
    "\n",
    "Второй вариант более общий, чем первый, так как наиболее вероятное $Y$ при данном $X$ можно найти как $\\text{argmax}_y P(X, Y)$. Третий вариант еще более общий, чем второй, так как в нем мы находим не только вероятности различных значений $Y$ при заданном $X$, но и вероятности различных значений $X$. Говоря языком теории вероятностей, во втором варианте мы ищем условную вероятность $Y$ при $X$, а в третьем совместное распределение $X$ и $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0e9f0-671b-43fd-91c2-6646148deebe",
   "metadata": {},
   "source": [
    "### Метод максимального правдоподобия\n",
    "\n",
    "Имея статистическую модель, мы хотим оценить ее параметры $\\theta$ на основании обучающих данных (выборки) $X$. Как мы помним, модель - это параметризованное семейство распределений. Значит зафиксировав параметры модели $\\theta$ мы получим некое распределение, с помощью которого для каждого элемента из $X$ сможем посчитать плотность вероятности $p(x) \\in \\mathbb{R}$.\n",
    "\n",
    "Поскольку все элементы выборки независимы и одинаково распределены ([i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)), то плотность вероятности для выборки равна произведению плотностей вероятностей для всех элементов:\n",
    "\n",
    "$p(X) = p(X_1, X_2, ..., X_N) = \\prod\\limits_{i=1}^N p(X_i)$\n",
    "\n",
    "Посчитав все $p(X_i)$, мы посчитаем плотность вероятности для всей выборки. Таким образом, каждому значению параметров $\\theta$ можно сопоставить число - плотность вероятности выборки $p(X|\\theta)$. Конкретные значения $\\theta$ можно назвать *гипотезами*, а величина $p(X|\\theta)$ называется *правдоподобием* выборки при заданном значении параметров. Нам лишь нужно найти значение $\\theta$, при котором правдоподобие максимально. Этот метод называется *методом максимума правдоподобия (MLE)* и по сути является уточнением формулировки задачи.\n",
    "\n",
    "$\\theta^{MLE} = \\underset{\\theta}{\\text{argmax}} p(X|\\theta) = \\underset{\\theta}{\\text{argmax}} \\prod\\limits_{i=1}^N p(X_i|\\theta)$\n",
    "\n",
    "С математической точки зрения это задача оптимизации, то есть поиска экстремума функции. Проблема однако в том, что $p(X)$ является произведением (см. формулу выше), и искать максимум такой функции технически сложно. Поиск максимума функции эквивалентен поиску максимума ее логарифма, а логарифм произведения расписывается как сумма логарифмов. Также по традиции к функции добавляется минус и ищется ее минимум:\n",
    "\n",
    "$\\theta^{MLE} = \\underset{\\theta}{\\text{argmax}} \\prod\\limits_{i=1}^N p(X_i|\\theta) = \\underset{\\theta}{\\text{argmin}} \\Big( -\\prod\\limits_{i=1}^N p(X_i|\\theta) \\Big) = \\underset{\\theta}{\\text{argmin}} \\Big( -\\ln\\prod\\limits_{i=1}^N p(X_i|\\theta) \\Big) = \\underset{\\theta}{\\text{argmin}} \\Big( -\\sum\\limits_{i=1}^N \\ln p(X_i|\\theta) \\Big)$\n",
    "\n",
    "В таком виде задача решается проще в плане оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4c394-a769-41a6-96bf-0c53518f4c36",
   "metadata": {},
   "source": [
    "### Байесовский вывод\n",
    "\n",
    "В методе максимума правдоподобия мы искали такое значение параметров $\\theta$, при котором имеющаяся выборка наиболее правдоподобна. Однако с точки зрения предметной области некоторые $\\theta$ могут быть сами по себе крайне маловероятными. Например, решая уравнение $x_1+x_2=1$, одним из возможных ответов будет $x_1 = 1000001, x_2 = -1000000$, но мы понимаем, что в большинстве задач такой ответ намного менее вероятен, чем, скажем, ответ $x_1 = 0.5, x_2 = 0.5$, хотя эти решения одинаково точно соответствуют уравнению. Иными словами, разные значения $\\theta$ априорно (еще до получения выборки) имеют разные вероятности.\n",
    "\n",
    "Формулировка задачи оптимизации, которые учитывает не только экспериментальные данные, но и априорное распределение вероятностей для $\\theta$, называется *методом апостериорного максимума*. Кроме того, иногда нас интересует не только максимум правдоподобия или апостериорный максимум (то есть единственное наиболее вероятное значение $\\theta$), но и распределение вероятностей по всем значениям $\\theta$ после эксперимента.\n",
    "\n",
    "Подробнее о байесовском выводе я писал в обзоре статьи [Frequentism and Bayesianism: A Python-driven Primer]($Frequentism and Bayesianism: A Python-driven Primer$) и в заметке [О байесовском подходе]($О байесовском подходе$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c178702-3c1b-4821-bb98-7d0f98c0635d",
   "metadata": {},
   "source": [
    "### Генеративные и дискриминативные модели\n",
    "\n",
    "Вернемся к трем вариантам статистических моделей:\n",
    "\n",
    "1. $Y(X)$\n",
    "2. $P(Y|X)$\n",
    "3. $P(X, Y)$.\n",
    "\n",
    "Если моделируется распределение $P(X, Y)$ (или $P(X)$, если нет целевой переменной), то модель называется **генеративной моделью**. Если же моделируется распределение $P(Y|X)$ или функция $Y(X)$, то модель называется **дискриминативной моделью**. Таким образом, генеративные модели более общие, чем дискриминативные. Генеративные модели названы так потому, что они моделируют распределение, из которого сгенерированы данные. Дискриминативные модели имеют такое название потому, что с их помощью можно различать (discriminate) значения $y$, используя $x$.\n",
    "\n",
    "Например, нейронная сеть для классификации это дискриминативная модель, которая ищет $P(y|x)$. Приняв на вход значение $x$, нейронная сеть выдает значения $P(y|x)$ для всех возможных $y$. Но эта модель ничего не говорит о распределении значений $x$.\n",
    "\n",
    "Генеративные модели часто используются в обучении без разметки (unsupervised learning) и кластеризации, а в задачах классификации и регрессии чаще используются дискриминативные модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486d0fa-0433-4e50-bf78-47fd9a81a69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
