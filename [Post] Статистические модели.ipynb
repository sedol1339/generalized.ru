{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b146e0-3064-4be9-b39d-81ce6322da1b",
   "metadata": {},
   "source": [
    "В этой статье мы разберем понятие статистической модели, которое лежит в основе многих задач статистики и машинного обучения.\n",
    "\n",
    "Для дальнейшего изложения понадобится повторить базовые понятия теории вероятностей: [распределение](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9) и выборка. [Непрерывное](http://mathprofi.ru/nepreryvnaya_sluchaynaya_velichina.html) распределение можно задать функцией плотности вероятности, [дискретное](http://mathprofi.ru/sluchainaya_velichina.html) - функцией вероятности каждого элемента. Выборкой из распределения размером $N$ называется $N$ элементов, полученных из распределения. Это не обязательно числа, а могут быть вектора или даже изображения, в зависимости от того, на каком множестве задано наше распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd289ac-5884-44b6-a963-71aa2b36396c",
   "metadata": {},
   "source": [
    "### Статистическая модель\n",
    "\n",
    "Статистическая модель вводятся для ответа на вопрос: *из какого распределения получена имеющаяся выборка данных*? Пусть существует некое распределение $\\Phi$, которое нам неизвестно. Мы имеем выборку размером $N$ элементов из этого распределения $X = \\{X_i\\}_{i=1}^N$. Мы вводим параметризованное семейство распределений $\\{\\phi_\\theta | \\theta \\in \\Theta\\}$, используя некую известную нам функцию $\\phi$. При этом мы надеемся, что искомое распределение $\\Phi$ принадлежит множеству ${\\phi_\\theta}$ или по крайней мере его можно аппроксимировать элементами этого множества. Задача состоит в том, чтобы подобрать оптимальные параметры $\\theta$, при которых выборка $X$ наиболее правдоподобна.\n",
    "\n",
    "Статистическая модель - это пара из выборки $X$ и семейства распределений $\\{\\phi_\\theta | \\theta \\in \\Theta\\}$. Таким образом, модель ничего не говорит об оптимальных значениях параметров, а лишь описывает среди какого множества распределений мы выполняем поиск. То есть модель является постановкой задачи, а не ее решением. В более простом случае нужно найти лишь одно наиболее вероятное значение $\\theta$, в более сложном случае (байесовский вывод) нужно оценить мат. ожидание $\\theta$ с учетом всех возможных значений $\\theta$ и их вероятностей.\n",
    "\n",
    "**Пример 1**. Мы имеем выборку $X$, полученную из нормального распределения $\\mathcal{N}_{\\mu, \\sigma}$ с неизвестными параметрами $\\mu, \\sigma$. Задача - оценить эти параметры. Моделью в этом случае выглядит так: $(X, \\{\\mathcal{N}_{\\mu, \\sigma} | \\mu \\in \\mathbb{R}, \\sigma \\in \\mathbb{R}\\})$. Заметим, что если выборка $X$ на самом деле была получена не из нормального распределения, то наша модель неадекватна.\n",
    "\n",
    "**Пример 2**. Мы имеем изображение звездного поля, полученное с помощью телескопа. Изображение можно рассматривать как сумму попавших в объектив фотонов, каждый из которых является выборкой из распределения $\\Phi$, которое является суммой [функций рассеяния точки](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D1%80%D0%B0%D1%81%D1%81%D0%B5%D1%8F%D0%BD%D0%B8%D1%8F_%D1%82%D0%BE%D1%87%D0%BA%D0%B8). Каждая функция рассеяния соответствует одной звезде, а коэффициент перед ней соответствует яркости звезды. Нужно по изображению оценить координаты звезд и их яркость, то есть найти параметры распределения $\\Phi$. Это может быть сложной задачей если звезды расположены настолько близко, что их функции рассеяния \"сливаются\" друг с другом.\n",
    "\n",
    "**Пример 3**. Мы имеем набор изображений рукописных цифр 28x28 пикселей [MNIST](https://ru.wikipedia.org/wiki/MNIST_(%D0%B1%D0%B0%D0%B7%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)). Этот набор является выборкой из распределения вероятностей $\\Phi$ всех возможных рукописных изображений цифр. Если мы сможем аппроксимировать $\\Phi$, то сможем генерировать новые цифры. Можно рассмотреть и немного другой пример: мы имеем выборку из распределения $\\Phi$, заданного на множестве пар (изображение, номер цифры). То есть мы имеем изображения и ответы к ним: какая цифра изображена. Это значит, что плотность вероятности $\\Phi$ имеет следующий вид: \n",
    "\n",
    "$\\Phi: \\mathbb{R}^{28 \\times 28} \\times \\{0, 1, 2, \\ldots, 9\\} \\to \\mathbb{R}$.\n",
    "\n",
    "Аргументами функции является изображение ($\\mathbb{R}^{28 \\times 28}$) и цифра от 0 до 9, значением функции является плотность вероятности появления такой пары в распределении. Если мы найдем $\\Phi$ или хотя бы сможем его аппроксимировать, то мы решим задачу распознавания цифр. Например, по заданному изображению мы переберем все возможные \"ответы\" и найдем тот ответ, для которого плотность вероятности наибольшая, и так определим какая цифра изображена.\n",
    "\n",
    "### Статистические модели в машинном обучении\n",
    "\n",
    "Распознавание MNIST, приведенное в примере выше - типичная задача машинного обучения. Это означает, что *модели машинного обучения обычно тоже являются статистическими моделями*. С их помощью мы пытаемся аппроксимировать неизвестное нам распределение вероятностей. Отличие статистики от машинного обучения лишь в том, что в машинном обучении искомые распределения вероятностей намного сложнее.\n",
    "\n",
    "Рассмотрим задачу машинного обучения, имеющую целевые данные $Y$ (что нужно предсказать) и исходные данные $X$ (на основании каких данных нужно сделать предсказание). Распределение на множестве пар (исходные + целевые данные) называется порождающим распределением. Саму модель машинного обучения можно описать в разных вариантах:\n",
    "\n",
    "1. $Y(X)$\n",
    "2. $P(Y|X)$\n",
    "3. $P(X, Y)$.\n",
    "\n",
    "Второй вариант более общий, чем первый, так как наиболее вероятное $Y$ при данном $X$ можно найти как $\\text{argmax}_y P(X, Y)$. Третий вариант еще более общий, чем второй, так как в нем мы находим не только вероятности различных значений $Y$ при заданном $X$, но и вероятности различных значений $X$. Говоря языком теории вероятностей, во втором варианте мы ищем условную вероятность $Y$ при $X$, а в третьем совместное распределение $X$ и $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0e9f0-671b-43fd-91c2-6646148deebe",
   "metadata": {},
   "source": [
    "### Метод максимального правдоподобия\n",
    "\n",
    "Имея статистическую модель, мы хотим оценить ее параметры $\\theta$ на основании обучающих данных (выборки) $X$. Как мы помним, модель - это параметризованное семейство распределений. Значит зафиксировав параметры модели $\\theta$ мы получим некое распределение, с помощью которого для каждого элемента из $X$ сможем посчитать плотность вероятности $p(x) \\in \\mathbb{R}$.\n",
    "\n",
    "Поскольку все элементы выборки независимы и одинаково распределены ([i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)), то плотность вероятности для выборки равна произведению плотностей вероятностей для всех элементов:\n",
    "\n",
    "$p(X) = p(X_1, X_2, ..., X_N) = \\prod\\limits_{i=1}^N p(X_i)$\n",
    "\n",
    "Посчитав все $p(X_i)$, мы посчитаем плотность вероятности для всей выборки. Таким образом, каждому значению параметров $\\theta$ можно сопоставить число - плотность вероятности выборки $p(X|\\theta)$. Конкретные значения $\\theta$ можно назвать *гипотезами*, а величина $p(X|\\theta)$ называется *правдоподобием* выборки при заданном значении параметров. Нам лишь нужно найти значение $\\theta$, при котором правдоподобие максимально. Этот метод называется *методом максимума правдоподобия (MLE)* и по сути является уточнением формулировки задачи.\n",
    "\n",
    "$\\theta^{MLE} = \\underset{\\theta}{\\text{argmax}} p(X|\\theta) = \\underset{\\theta}{\\text{argmax}} \\prod\\limits_{i=1}^N p(X_i|\\theta)$\n",
    "\n",
    "С математической точки зрения это задача оптимизации, то есть поиска экстремума функции. Проблема однако в том, что $p(X)$ является произведением (см. формулу выше), и искать максимум такой функции технически сложно. Поиск максимума функции эквивалентен поиску максимума ее логарифма, а логарифм произведения расписывается как сумма логарифмов. Также по традиции к функции добавляется минус и ищется ее минимум:\n",
    "\n",
    "$\\theta^{MLE} = \\underset{\\theta}{\\text{argmax}} \\prod\\limits_{i=1}^N p(X_i|\\theta) = \\underset{\\theta}{\\text{argmin}} \\Big( -\\prod\\limits_{i=1}^N p(X_i|\\theta) \\Big) = \\underset{\\theta}{\\text{argmin}} \\Big( -\\ln\\prod\\limits_{i=1}^N p(X_i|\\theta) \\Big) = \\underset{\\theta}{\\text{argmin}} \\Big( -\\sum\\limits_{i=1}^N \\ln p(X_i|\\theta) \\Big)$\n",
    "\n",
    "В таком виде задача решается проще в плане оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b6492-bc94-49f6-a32c-6d0de65d3a48",
   "metadata": {},
   "source": [
    "Часто именно выражение $-\\ln p(X_i|\\theta)$ выбирается в качестве функции потерь при обучении ML-моделей.\n",
    "\n",
    "### Пример\n",
    "\n",
    "Пусть мы обучаем нейронную сеть $\\text{Net}(x, \\theta)$, где $\\theta$ - веса сети, $x$ - входные данные. Нейронная сеть выдает одно число, и статистическую модель $p(y|x, \\theta)$ опишем таким образом: $p(y|x) = \\mathcal{N}(y; \\text{Net}(x, \\theta), 1/\\sqrt 2)$ (нормальное распределение с параметрами $\\mu = \\text{Net}(x, \\theta)$, $\\sigma = 1/\\sqrt 2$).\n",
    "\n",
    "Согласно модели, при заданном $\\theta$ каждая пара $X_i = (x_i, y_i)$ из обучающего датасета имеет следующую вероятность:\n",
    "\n",
    "$p(y_i|x_i, \\theta) = \\mathcal{N}(y_i; \\text{Net}(x_i, \\theta), 1/\\sqrt{2}) = \\frac{1}{\\sqrt\\pi} \\exp{(y_i - \\text{Net}(x_i, \\theta))^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51789d-2f48-4c59-8b0d-1206346daff0",
   "metadata": {},
   "source": [
    "Применяя метод максимального правдоподобия, мы ищем следующее значение параметров $\\theta$:\n",
    "\n",
    "$\\underset{\\theta}{\\text{argmin}} \\Big( -\\sum\\limits_{i=1}^N \\ln p(X_i|\\theta) \\Big)$\n",
    "\n",
    "Распишем элемент данной суммы (символ $\\propto$ означает пропорциональность):\n",
    "\n",
    "$-\\ln p(X_i|\\theta) = -\\ln p(y_i|x_i, \\theta) \\propto -\\ln \\exp {(y_i - \\text{Net}(x_i, \\theta))^2} = (y_i - \\text{Net}(x_i, \\theta))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408404f-324d-404e-b6d8-a194c97e899f",
   "metadata": {},
   "source": [
    "Таким образом, задача сводится к минимизации среднеквадратичного отклонения (MSE) на обучающем датасете. Любая ML-модель, которая минимизирует MSE на обучающем датасете, эквивалентна описанной статистической модели.\n",
    "\n",
    "Конечно, нет строгого правила, согласно которому функция потерь должна быть равна минус логарифму вероятности выборки. Вместо этого, мы можем в качестве функции потерь выбрать саму вероятность $p(X|\\theta)$. Однако тогда во-первых функцию потерь нужно будет максимизировать, а не минимизировать, во-вторых функция потерь для выборки будет уже не суммой, а произведением функций потерь на каждом примере, что неудобно и может привести к большим погрешностям вычислений.\n",
    "\n",
    "См. также [Функция потерь как выражение метрики на целевой переменной]($Функция потерь как выражение метрики на целевой переменной$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4c394-a769-41a6-96bf-0c53518f4c36",
   "metadata": {},
   "source": [
    "### Метод апостериорного максимума\n",
    "\n",
    "В методе максимума правдоподобия мы искали такое значение параметров $\\theta$, при котором имеющаяся выборка наиболее правдоподобна. Однако с точки зрения предметной области некоторые $\\theta$ могут быть сами по себе крайне маловероятными. Например, решая уравнение $x_1+x_2=1$, одним из возможных ответов будет $x_1 = 1000001, x_2 = -1000000$, но мы понимаем, что в большинстве задач такой ответ намного менее вероятен, чем, скажем, ответ $x_1 = 0.5, x_2 = 0.5$, хотя эти решения одинаково точно соответствуют уравнению. Иными словами, разные значения $\\theta$ априорно (еще до получения выборки) имеют разные вероятности.\n",
    "\n",
    "*Простая аналогия \"из жизни\". Если ваша жена долго не возвращается домой, то возможно перед домом остановилась орда монголов, которая не дает ей пройти, или в подъезде поселились тигры. Наблюдаемое явление (жена не приходит домой) будет очень правдоподобным в том случае, если верна одна из этих гипотез. Поэтому применение метода максимума правдоподобия приведет нас к таким гипотезам. Однако априорная вероятность таких гипотез ничтожна, поэтому байесовский вывод позволит в этом случае сделать более корректные предположения.*\n",
    "\n",
    "Формулировка задачи оптимизации, которые учитывает не только экспериментальные данные, но и априорное распределение вероятностей для $\\theta$, называется *методом апостериорного максимума*. В этом случае, согласно формуле Байеса, мы ищем не максимум правдоподобия, а максимум произведения правдоподобия $p(X_i|\\theta)$ на априорную вероятность $p(\\theta)$:\n",
    "\n",
    "$\\theta^{MAP} = \\underset{\\theta}{\\text{argmax}} \\Big( p(\\theta) \\prod\\limits_{i=1}^N p(X_i|\\theta) \\Big) = \\underset{\\theta}{\\text{argmin}} \\Big( - \\ln p(\\theta) - \\sum\\limits_{i=1}^N \\ln p(X_i|\\theta) \\Big)$\n",
    "\n",
    "Добавление априорных вероятностей $p(\\theta)$ называется регуляризацией. По формуле нетрудно видеть, что чем больше доступно обучающих данных, тем меньший эффект оказывают априорные гипотезы. Это соответствует здравому смыслу: мы готовы принять даже саму неправдоподобную гипотезу, если доступно очень много подтверждающих ее фактов, либо эти факты очень убедительны. Из этого можно сделать вывод о том, что регуляризация наиболее важна в том случае, когда данных для обучения доступно мало, либо они недостаточно разнообразны."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f78b5e-d3ed-4f99-af55-cc8f91620a4d",
   "metadata": {},
   "source": [
    "Можно утверждать, что любое применение метода максимального правдоподобия является частным случаем метода апостериорного максимума. В методе максимального правдоподобия мы явно не используем априорную вероятность $p(\\theta)$, но неявно $p(\\theta)$ одинаково для всех рассматриваемых гипотез и равно нулю для всех не рассматриваемых гипотез.\n",
    "\n",
    "Например, пусть наша модель - однослойная нейронная сеть, тогда искомое $\\theta$ - это веса сети. Допустим мы не накладываем никакой явной регуляризации и минимизируем функцию потерь на некоем датасете $X = \\{x_1, \\dots, x_n\\}$. Если значение функции потерь мы интерпретируем как $-\\ln p(X|\\theta)$, то значит мы ищем такое $\\theta$, при котором $X$ наиболее вероятно, то есть используем метод максимального правдоподобия. Поскольку этот метод является частным случаем метода апостериорного максимума, то значит мы используем метод апостериорного максимума. При этом априорная вероятность $p(\\theta)$ одинакова для всех $\\theta$, соответствующих нашей модели, и равна нулю для всех $\\theta$, не соответствующих нашей модели (например, для весов двухслойной нейронной сети)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d7c2f-adf1-4c4e-881a-f0001a67c734",
   "metadata": {},
   "source": [
    "### Выбор априорного распределения\n",
    "\n",
    "Выбрав статистическую модель для решения задачи, мы задаем множество допустимых гипотез $\\theta$. Без дополнительной регуляризации это соответствует априорному распределению $p(\\theta)$, равному некой константе для допустимых $\\theta$ и нулю для недопустимых $\\theta$. Дополнительная регуляризация (например L2-регуляризация) означает корректировку $p(\\theta)$. Таким образом, чтобы задать априорное распределение $p(\\theta)$, нужно:\n",
    "\n",
    "1. Выбрать статистическую модель, то есть рассматриваемое семейства гипотез $\\Theta$, для которых априорная вероятность $p(\\theta)$ ненулевая.\n",
    "2. Опционально: наложить дополнительную регуляризацию, меняющую соотношение $p(\\theta)$ для разных гипотез.\n",
    "\n",
    "Чем мы должны руководствоваться, выбирая априорное распределение $p(\\theta)$? Переформулируем вопрос: как выбрать модель и регуляризацию? Конечно, машинное обучение было бы намного проще, если бы на этот вопрос существовал простой ответ. В целом, для этого мы должны сделать предположение о том, как может выглядеть алгоритм, решающий поставленную задачу. Более подробно об этом вопросе я писал в статье [Априорные гипотезы и регуляризация в машинном обучении]($Априорные гипотезы и регуляризация в машинном обучении$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876da5f6-ac1e-480f-b7a9-e5394e0223f1",
   "metadata": {},
   "source": [
    "### Байесовские методы в статистических моделях\n",
    "\n",
    "В описанном выше методе апостериорного максимума мы ищем наиболее вероятное значение $\\theta$ как моду апостериорного распределения:\n",
    "\n",
    "$\\underset{\\theta}{\\max} p(\\theta|X)$\n",
    "\n",
    "Вместо моды можно искать *мат. ожидание* апостериорного распределения:\n",
    "\n",
    "$\\int \\theta\\ p(\\theta|X)\\ d\\theta$\n",
    "\n",
    "Такой подход часто и называется байесовским выводом, однако он является вычислительно сложным, так как требует интегрирования. Часто выполнить интегрирование в явном виде невозможно. Например, в случае нейронной сети $\\theta$ обозначает веса сети, и интегрирование по всем $\\theta$ означает интегрирование по всем возможным значениям весов сети, то есть полный перебор весов сети, который обычно невозможно выполнить. На практике для интегрирования обычно используют приближенные методы, самым известным из которых является Markov chain Monte Carlo (MCMC).\n",
    "\n",
    "Хорошее введение в байесовские методы дано в книге [Bayesian Learning for Neural Networks]($Bayesian Learning for Neural Networks$) (1995), глава 1 \"Introduction\". Можно посмотреть также статью [Frequentism and Bayesianism A Python-driven Primer](https://arxiv.org/abs/1411.5018) (VanderPlas, 2014), на которую я делал [обзор]($Frequentism and Bayesianism A Python-driven Primer$), и статью [Bayesian Workflow]($Bayesian Workflow$) (2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c178702-3c1b-4821-bb98-7d0f98c0635d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Генеративные и дискриминативные модели\n",
    "\n",
    "Вернемся к трем вариантам статистических моделей:\n",
    "\n",
    "1. $Y(X)$\n",
    "2. $P(Y|X)$\n",
    "3. $P(X, Y)$.\n",
    "\n",
    "Если моделируется распределение $P(X, Y)$ (или $P(X)$, если нет целевой переменной), то модель называется **генеративной моделью**. Если же моделируется распределение $P(Y|X)$ или функция $Y(X)$, то модель называется **дискриминативной моделью**. Таким образом, генеративные модели более общие, чем дискриминативные. Генеративные модели названы так потому, что они моделируют распределение, из которого сгенерированы данные. Дискриминативные модели имеют такое название потому, что с их помощью можно различать (discriminate) значения $y$, используя $x$.\n",
    "\n",
    "Например, нейронная сеть для классификации - это дискриминативная модель, которая оценивает $P(y|x)$. Приняв на вход значение $x$, нейронная сеть выдает значения $P(y|x)$ для всех возможных $y$. Но эта модель ничего не говорит о распределении значений $x$. Генеративные модели часто используются в обучении без разметки (unsupervised learning) и кластеризации, а в задачах классификации и регрессии чаще используются дискриминативные модели.\n",
    "\n",
    "Генеративные модели могут моделировать распределение $P(X)$ или $P(X, Y)$, но пара случайных величин - это тоже случайная величина, поэтому без ограничения общности будем считать, что моделируется $P(X)$. Генеративные модели могут быть двух основных типов:\n",
    "\n",
    "1. Модель позволяет оценить вероятность или плотность вероятности для произвольного $X$\n",
    "2. Модель позволяет семплировать из распределения $P(X)$, то есть работает как генератор величин из распределения\n",
    "\n",
    "При наличии неограниченных вычислительных ресурсов оба случая эквивалентны: имея $P(X)$ для всех $X$ можно семплировать примеры из распределения, а семплируя примеры можно оценить $P(X)$. Однако в условиях ограниченных вычислительных ресурсов эти два случая отличаются. Могут быть и промежуточные случаи, например в языковых моделях модель распределения $P(x)$ факторизуется как $P(x) = \\prod_t P(x_t | x_{<t})$ (см. обзор на [GPT и BERT]($GPT и BERT$)) - такая формула позволяет как оценивать вероятность, так и семплировать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f8284-1c8b-4cb4-9adf-661c4e144d6f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary></summary>\n",
    "Модель, text-to-image модель, моделирующая распределение $P(\\text{image}\\ |\\ \\text{text})$, также можно считать дискриминативной по определению, несмотря на то, что она *генерирует* изображения. Однако в целом любое совместное распределение $P(x)$ можно представить как условное распределение $P(x|y)$, задав некое тривиальное условие, поэтому граница между генеративными и дискриминативными моделями условна. Как мне кажется, генеративными моделями стоит называть  модели, моделирующие некое сложное многомерное распределение при условии простого вида или без условия, тогда как дискриминативными - наоборот модели, моделирующие распределение простого вида при условиии сложного вида.\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
