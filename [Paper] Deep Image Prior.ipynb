{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4281c4-7be9-4263-83b6-5a7aa10eb1ec",
   "metadata": {},
   "source": [
    "В данной статье описан интересный проход к некоторым image-to-image задачам, таким как уменьшение шума на изображении (denoising), увеличение разрешения (super-resolution) и дорисовывание недостающих участков на изображении (inpainting). При этом *не используется никакого обучающего датасета*, а используется лишь то изображение, над которым нужно выполнить преобразование. Интересен не только метод сам по себе, но и выводы, которые из него можно сделать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c6fb8-74e3-418a-8f02-80b9bb6922fe",
   "metadata": {},
   "source": [
    "### Bling denoising\n",
    "\n",
    "Задачей blind denoising называется задача уменьшения шума на изображении $x_{noisy}$, при этом вероятностное распределение шума заранее неивестно. Это может быть, например, наложенный белый шум или артефакты jpeg.\n",
    "\n",
    "Создадим случайно инициализированную сверточную нейронную сеть $f(z, \\theta)$, которая преобразует тензор признаков $z$ в изображение, используя веса $\\theta$. Например, можно взять сеть [U-Net]($U-Net: Convolutional Networks for Biomedical Image Segmentation$), если интерпретировать ее входные данные не как изображение, а как тензор признаков. В качестве $z$ будем использовать массив случайных чисел. Будем решать следующую задачу оптимизации (например, градиентным спуском):\n",
    "\n",
    "$\\|f($z$, \\theta) - x_{noisy}\\|^2 \\to \\underset{\\theta}{\\min}$\n",
    "\n",
    "То есть мы оптимизируем веса сети так, чтобы случайный шум она преобразовывала в исходное изображение $x_{noisy}$. Если долго и упорно оптимизировать $\\theta$, то как правило $f($z$, \\theta)$ станет почти точной копией $x_{noisy}$, особенно если в сети очень много параметров. Но если останавливать процесс оптимизации \"на полпути\" (early stopping), то $f($z$, \\theta)$ станет приблизительной копией $x_{noisy}$, избавленной от шума. То есть модель успевает обучиться воссоздавать детали изображения, но не успевает обучиться воссоздавать мелкодисперсный шум."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da975b04-8dfe-43f5-be9a-6f09042e7d43",
   "metadata": {},
   "source": [
    "Авторы отмечают, что оптимизацию можно производить не только по весам сети $\\theta$, но и по тензору признаков $z$, хотя они так не делают.\n",
    "\n",
    "Интересно, что процесс оптимизации сходится достаточно быстро, если $x_{noisy}$ является настоящим изображением (рисунком или фотографией), и намного медленнее, если в качестве $x_{noisy}$ взять случайный шум. На иллюстрации ниже показаны графики функции потерь для исходных изображений (Image), изображений с наложенным шумом (Image + noise), изображений с переставленными пикселями (Image shuffled) и случайного шума ($U(0, 1)$ noise).\n",
    "\n",
    "> Naturally-looking images result in much faster convergence, whereas noise is rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0711c04-43f4-4099-81c6-8f5e0e8a77d9",
   "metadata": {},
   "source": [
    "<img src=\"assets/deepimageprior.jpg\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728b230-8947-4a37-85ac-98ac6de3c0d1",
   "metadata": {},
   "source": [
    "Здесь, правда остается, вопрос: связана ли быстрая сходимость с тем, что изображение выглядит натурально? Вполне возможно, что быстрая сходимость обусловлена лишь близкими значениями находящихся рядом пикселей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e361f46-fc27-42dc-9ad9-17fbc76da162",
   "metadata": {},
   "source": [
    "### Super-resolution\n",
    "\n",
    "В задаче повышения разрешения изображений используется аналогичный подход: увеличенное изображение мы получаем как $x_{upscaled} = f(z, \\theta)$. Чтобы сравнить $x_{upscaled}$ с исходным $x_{orig}$, изображение $x_{upscaled}$ уменьшается до исходного размера каким-либо дифференцируемым алгоритмом, например Lanczos:\n",
    "\n",
    "$\\|\\textit{LanczosDownscale}(f($z$, \\theta)) - x_{orig}\\|^2 \\to \\underset{\\theta}{\\min}$\n",
    "\n",
    "В сравнении с bicubic upsampling, предложенный метод обеспечивает большую резкость границ на увеличенном изображении. Качество upsmpling'а приближается к качеству, достигаемому нейронными сетями, которые обучаются на больших датасетах.\n",
    "\n",
    "На изображении ниже сравниваются разные способы восстановить фотографию зебры, предварительно уменьшенную до малого размера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d4156-3f09-4e8c-81b7-88f6dabb6463",
   "metadata": {},
   "source": [
    "<img src=\"assets/deepimageprior3.jpg\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b134a4f-bf37-4bdc-a3ac-f6c52450bdc7",
   "metadata": {},
   "source": [
    "\"No prior\" означает непосредственную оптимизацию среднеквадратичного отклонения без использования сверточной сети:\n",
    "\n",
    "$\\|\\textit{LanczosDownscale}(z) - x_{orig}\\|^2 \\to \\underset{\\theta}{\\min}$.\n",
    "\n",
    "\"TV prior\" означает использование *total variation*, описанного в [другой работе]($Understanding Deep Image Representations by Inverting Them$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9ac95-bde1-414e-b20e-48df38e4ee62",
   "metadata": {},
   "source": [
    "### Inpainting\n",
    "\n",
    "В этой задаче исходными данными является изображение $x_{orig}$ и бинарная маска $x_{mask}$. Требуется реалистично дорисовать те участки изображения, где $x_{mask} = 0$. Такую задачу решает, например, инструмент \"заполнение с учетом содержимого\" в Photoshop.\n",
    "\n",
    "Чтобы применить описанный метод к задаче inpainting, достаточно минимизировать среднеквадратичное отклонение по тем пикселям, где $x_{mask} = 1$. \n",
    "\n",
    "$\\|(f($z$, \\theta) - x_{orig}) \\odot x_{mask}\\|^2 \\to \\underset{\\theta}{\\min}$\n",
    "\n",
    "То есть сверточная сеть генерирует изображение, которое должно совпасть с исходным везде, кроме замаскированной области. При этом сгенерированный участок, который соответствует замаскированной области, мы считаем результатом inpainting'а.\n",
    "\n",
    "Выбор learning rate при этом играет определяющую роль:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109c29c-1bbf-47a3-88bb-eabe81330eed",
   "metadata": {},
   "source": [
    "<img src=\"assets/deepimageprior4.jpg\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1fc91d-7247-4b60-901c-08c6c3dc94f1",
   "metadata": {},
   "source": [
    "Вполне очевидно, что случайно инициализированная нейронная сеть не сможет дорисовать такие детали, которые больше нигде не встречались в исходном изображении. Например, не получится дорисовать голову кота, закрытую маской, поскольку в нейронную сеть не заложена информация о том, как выглядит кот, и эту информацию взять неоткуда. При данном подходе маска будет заполнена такими текстурами, которые присутствуют где-то еще вокруг маски."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e3e3c-eedf-45f5-8576-7be83018cd40",
   "metadata": {},
   "source": [
    "### Обобщение\n",
    "\n",
    "В общем случае предложенный метод авторы описывают как \"минимизацию энергии\" между сгенерированным и исходным изображением:\n",
    "\n",
    "$E(f(z, \\theta), x_{orig}) \\to \\underset{\\theta}{\\min}$\n",
    "\n",
    "Функция $E$ зависит от задачи, например, в задаче шумоподавления $E(x, y) = \\|x - y\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711d700-c8d7-4572-8930-c1a6a001fabc",
   "metadata": {},
   "source": [
    "Введение понятия \"deep image prior\" авторы поясняют следующим образом:\n",
    "\n",
    "> In this work, we ... use the implicit prior captured by the neural network parametrization, as follows:\n",
    "\n",
    "> $\\theta^* = \\underset{\\theta}{\\text{argmin}} E(f_\\theta(z); x_0),\\ \\ \\ \\ \\ \\ \\ \\ \\ x^* = f_{\\theta^*}(z) \\tag{2}$\n",
    "\n",
    "> Since no aspect of the network $f_\\theta$ is learned from data beforehand, such deep image prior is effectively handcrafted.\n",
    "\n",
    "> The prior defined by eq. $(2)$ is implicit and does not define a proper probability distribution in the image space. Nevertheless, it is possible to draw \"samples\" (in the loose sense) from this prior by taking random values of the parameters $\\theta$ and looking at the generated image $f_\\theta(z)$. In other words, we can visualize the starting points of the optimization process eq. (2) before fitting the parameters to the noisy image. Figure 5 shows such  “samples” from the deep priors captured by different hourglass-type architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a844c-5643-4d9f-aeec-f3b381fbc325",
   "metadata": {},
   "source": [
    "> <img src=\"assets/deepimageprior2.jpg\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fba931-12e2-4380-9926-6c10bc754a84",
   "metadata": {},
   "source": [
    "> Fig. 5: \"Samples\" from the deep image prior. We show images that are produced by ConvNets with random weights from independent random uniform noise. The scale of structures naturally changes with the depth of the network.\n",
    "\n",
    "> Adding skip connections results in images that contain structures of different characteristic scales, as is desirable for modeling natural images. It is therefore natural that such architectures are the most popular choice for generative ConvNets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b6f08d-1c5a-4d17-8508-f345f0f04d46",
   "metadata": {},
   "source": [
    "В байесовском выводе под понятием prior понимается пространство гипотез, в котором осуществляется поиск, и то, какие гипотезы из этого пространства мы предпочитаем в большей или меньшей степени.\n",
    "\n",
    "Например, в задаче inpainting, имея $x_{orig}$, мы *ищем ближайший элемент в пространстве $X$ всех изображений, сгенерированных сверточной сетью*:\n",
    "\n",
    "$X = \\{f(z, \\theta)\\ |\\ \\theta \\in \\Theta, z \\in Z\\}$\n",
    "\n",
    "(строго говоря, это будет так, если мы будем выполнять оптимизацию также и по $z$, авторы упоминают о такой возможности)\n",
    "\n",
    "> ...while it is also possible to optimize over the code z, in our experiments we do not do so.\n",
    "\n",
    "Пространство $X$ авторы и называют deep image prior. Поиск ближайшего элемента в $X$ можно применить в различных задачах, связанных с исправлением \"повреждений\" в изображении:\n",
    "\n",
    "> Our approach does not require a model for the image degradation process that it needs to revert. This allows it to be applied in a “plug-and-play” fashion to image restoration tasks, where the degradation process is complex and/or unknown and where obtaining realistic data for supervised training is difficult.\n",
    "\n",
    "Как мне кажется, в данном подходе все же есть некоторые проблемы. Во-первых, вероятно в $X$ содержатся практически все возможные изображения, так как количество параметров в сверточных сетях обычно во много раз превышает количество пикселей в изображении, и в результате система уравнений $x = f(\\theta, z)$, решаемая относительно $\\theta$, становится недоопределенной и имеет много решений. Это подтверждается тем фактом, что в задаче шумоподавления длительная оптимизация $\\theta$ приводит к исходному, зашумленному изображению, из-за чего необходима ранняя остановка. Также в $X$ содержатся всевозможные размытые изображения, поэтому маловероятно, что задачу обращения размытия (deblurring) возможно решить таким методом. И наконец, deep image prior никак не позволяет дополнить изображение сложными деталями исходя из его семантики, например дорисовать руку человека, закрытую маской. Но это, конечно, не уменьшает значимости данной работы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77d47b-6ec4-4090-8014-3ebbd7cee3dd",
   "metadata": {},
   "source": [
    "### Наличие обучающих данных\n",
    "\n",
    "Авторы утверждают, что в их методе вообще не происходит обучения:\n",
    "\n",
    "> In this work, we show that, in fact, not all image priors must be learned from data; instead, a great deal of image statistics are captured by the structure of generator ConvNets, independent of learning. This is especially true for the statistics required to solve certain image restoration problems, where the image prior must supplement the information lost in the degradation processes.\n",
    "\n",
    "> ...no aspect of the network is learned from data and illustrates the power of the image prior implicitly captured by the network structure. To the best of our knowledge, this is the first study that directly investigates the prior captured by deep convolutional generative networks independently of learning the network parameters from images.\n",
    "\n",
    "Предложенный метод интересен своей простотой и эффективностью, но сделанный вывод звучит несколько странно. Кажется необоснованным утверждение о том, что метод не использует обучающие данные. В каком-то смысле обучающими данными можно считать само изображение, на котором проводится оптимизация. Сеть обучается рисовать текстуры на участках, не закрытых маской, и дорисовывает такие же текстуры на участках, закрытых маской.\n",
    "\n",
    "Особенно это будет видно, если inpainting будет проводиться на изображении очень большого размера (намного большего, чем рецептивное поле сети), например, $10^5 \\times 10^5$ пикселей, некоторые небольшие части которого закрыты маской. По количеству пикселей это изображение будет сопоставимо с небольшим обучающим датасетом. Если не учитывать перекрытие рецептивных полей, то можно разрезать изображение на части, и задача станет эквивалентна обучению одной и той же сети дорисовывать сразу несколько изображений $x_i$, каждое по своему $z_i$. Сети придется выучивать много разных типов текстур, чтобы дорисовывать недостающие участки. Задача станет проще, если вместе с $\\theta$ мы будем оптимизировать и $z_i$ (что авторы работы не запрещают).\n",
    "\n",
    "В такой формулировке *алгоритм станет почти эквивалентным описанному в работе [Deconvolutional Networks]($Deconvolutional Networks$)* (2010). Отличие лишь в цели: в данной работе целью является обработка исходного изображения (дорисовывание, шумоподавление и т. д.) а в работе Deconvolutional Networks целью было нахождение карты признаков для последующей классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04dd1c7-a1b8-48bd-8be0-2e6ac5f03d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
